{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用结巴分词对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载评测数据集包含了\n",
    "\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from datasets import Dataset\n",
    "dataset_path=\"../data/rag_data/eval/eval_dataset2\"\n",
    "if os.path.isdir(dataset_path):\n",
    "    dataset=Dataset.load_from_disk(dataset_path)\n",
    "\n",
    "# 因为要调用文心评测 这里只用数据集的一个样本\n",
    "dataset_mini=dataset.select(range(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以使用ERNIE-Bot为，使用qianfan-sdk先定义自己的模型\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "import os\n",
    "import qianfan\n",
    "import pandas as pd\n",
    "\n",
    "QIANFAN_ACCESS_KEY=\"eK8QT20CEUvhggAoO54HaSqI\"\n",
    "QIANFAN_SECRET_KEY=\"AMEbJ2sLJikNvSLublIikzGpBnig10py\"\n",
    "chat = QianfanChatEndpoint(model=\"ERNIE-3.5-8K\", qianfan_ak=QIANFAN_ACCESS_KEY, qianfan_sk=QIANFAN_SECRET_KEY,request_timeout=120)\n",
    "vllm = LangchainLLMWrapper(chat)\n",
    "\n",
    "v_embeddings = QianfanEmbeddingsEndpoint(\n",
    "               qianfan_ak=QIANFAN_ACCESS_KEY,\n",
    "               qianfan_sk=QIANFAN_SECRET_KEY,\n",
    "           )\n",
    "\n",
    "# 然后重新指定各评价指标使用的llm\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "faithfulness.llm = vllm\n",
    "answer_relevancy.llm = vllm\n",
    "answer_relevancy.embeddings = v_embeddings\n",
    "\n",
    "context_recall.llm = vllm\n",
    "context_precision.llm = vllm\n",
    "\n",
    "# 重新一键式测评\n",
    "result = evaluate(\n",
    "    dataset_mini,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n",
    "df.head()\n",
    "df.to_csv('../data/rag_data/eval/evaleval_result.csv', index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/rag_data/eval/evaleval_result.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用jieba分词后 通过ntlk计算bleu  和  计算rouge  其中ronge是字典 里面有 1，2，l  里面还有r p l\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu \n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from rouge_chinese import Rouge\n",
    "import jieba # you can use any other word cutting library\n",
    "\n",
    "def compute_rouge_blue(answer_list,ground_truth_list):\n",
    "\n",
    "    rouge = Rouge()\n",
    "    chencherry = SmoothingFunction()\n",
    "\n",
    "    rouge_score=[]\n",
    "    bleu_score=[]\n",
    "    for i in zip(answer_list,ground_truth_list):\n",
    "        hypothesis=i[0]\n",
    "        hypothesis_iter=jieba.cut(hypothesis)\n",
    "        hypothesis = ' '.join(hypothesis_iter) \n",
    "\n",
    "        hypothesis_iter=jieba.cut(hypothesis) # 使用一次要重新cut\n",
    "        hypothesis_bleu_format=list(hypothesis_iter)\n",
    "\n",
    "\n",
    "        reference=i[1]\n",
    "        reference_iter=jieba.cut(reference)\n",
    "        reference = ' '.join(reference_iter)\n",
    "\n",
    "        reference_iter=jieba.cut(reference)\n",
    "        reference_bleu_format=list(reference_iter)\n",
    "\n",
    "\n",
    "        rouge_score.append(rouge.get_scores(hypothesis, reference))\n",
    "        bleu_score.append(sentence_bleu([reference_bleu_format], hypothesis_bleu_format,smoothing_function=chencherry.method1) )\n",
    "    \n",
    "    return  rouge_score,bleu_score\n",
    "rouge_score,bleu_score=compute_rouge_blue(dataset_mini['answer'],dataset_mini['ground_truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1_r,rouge_1_p,rouge_1_f=[],[],[]\n",
    "\n",
    "rouge_2_r,rouge_2_p,rouge_2_f=[],[],[]\n",
    "\n",
    "rouge_l_r,rouge_l_p,rouge_l_f=[],[],[]\n",
    "\n",
    "for i in rouge_score:\n",
    "\n",
    "    rouge_1_r.append(i[0]['rouge-1']['r'])\n",
    "    rouge_1_p.append(i[0]['rouge-1']['p'])\n",
    "    rouge_1_f.append(i[0]['rouge-1']['f'])\n",
    "\n",
    "    rouge_2_r.append(i[0]['rouge-2']['r'])\n",
    "    rouge_2_p.append(i[0]['rouge-2']['p'])\n",
    "    rouge_2_f.append(i[0]['rouge-2']['f'])\n",
    "\n",
    "    rouge_l_r.append(i[0]['rouge-l']['r'])\n",
    "    rouge_l_p.append(i[0]['rouge-l']['p'])\n",
    "    rouge_l_f.append(i[0]['rouge-l']['f'])\n",
    "\n",
    "df['rag_rouge_1_r']=rouge_1_r\n",
    "df['rag_rouge_1_p']=rouge_1_p\n",
    "df['rag_rouge_1_f']=rouge_1_f\n",
    "\n",
    "df['rag_rouge_2_r']=rouge_2_r\n",
    "df['rag_rouge_2_p']=rouge_2_p\n",
    "df['rag_rouge_2_f']=rouge_2_f\n",
    "\n",
    "df['rag_rouge_l_r']=rouge_l_r\n",
    "df['rag_rouge_l_p']=rouge_l_p\n",
    "df['rag_rouge_l_f']=rouge_l_f\n",
    "\n",
    "df['rag_bleu_score']=bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "llm_answers_path=\"../data/rag_data/eval/llm_answers.json\"\n",
    "\n",
    "with open(llm_answers_path,\"r\",encoding='utf-8') as file:\n",
    "    llm_answers_json=json.load(file)\n",
    "    \n",
    "rouge_score,bleu_score=compute_rouge_blue([item['llm_answers'] for item in llm_answers_json],dataset_mini['ground_truth'])\n",
    "rouge_score,bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1_r,rouge_1_p,rouge_1_f=[],[],[]\n",
    "\n",
    "rouge_2_r,rouge_2_p,rouge_2_f=[],[],[]\n",
    "\n",
    "rouge_l_r,rouge_l_p,rouge_l_f=[],[],[]\n",
    "\n",
    "for i in rouge_score:\n",
    "\n",
    "    rouge_1_r.append(i[0]['rouge-1']['r'])\n",
    "    rouge_1_p.append(i[0]['rouge-1']['p'])\n",
    "    rouge_1_f.append(i[0]['rouge-1']['f'])\n",
    "\n",
    "    rouge_2_r.append(i[0]['rouge-2']['r'])\n",
    "    rouge_2_p.append(i[0]['rouge-2']['p'])\n",
    "    rouge_2_f.append(i[0]['rouge-2']['f'])\n",
    "\n",
    "    rouge_l_r.append(i[0]['rouge-l']['r'])\n",
    "    rouge_l_p.append(i[0]['rouge-l']['p'])\n",
    "    rouge_l_f.append(i[0]['rouge-l']['f'])\n",
    "\n",
    "df['llm_rouge_1_r']=rouge_1_r\n",
    "df['llm_rouge_1_p']=rouge_1_p\n",
    "df['llm_rouge_1_f']=rouge_1_f\n",
    "\n",
    "df['llm_rouge_2_r']=rouge_2_r\n",
    "df['llm_rouge_2_p']=rouge_2_p\n",
    "df['llm_rouge_2_f']=rouge_2_f\n",
    "\n",
    "df['llm_rouge_l_r']=rouge_l_r\n",
    "df['llm_rouge_l_p']=rouge_l_p\n",
    "df['llm_rouge_l_f']=rouge_l_f\n",
    "\n",
    "df['llm_bleu_score']=bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision    0.840000\n",
      "faithfulness         0.915686\n",
      "answer_relevancy     0.776482\n",
      "context_recall       0.766000\n",
      "rag_rouge_1_r        0.407527\n",
      "rag_rouge_1_p        0.429279\n",
      "rag_rouge_1_f        0.383734\n",
      "rag_rouge_2_r        0.204050\n",
      "rag_rouge_2_p        0.218466\n",
      "rag_rouge_2_f        0.187506\n",
      "rag_rouge_l_r        0.322901\n",
      "rag_rouge_l_p        0.309480\n",
      "rag_rouge_l_f        0.272518\n",
      "rag_bleu_score       0.218051\n",
      "llm_rouge_1_r        0.381247\n",
      "llm_rouge_1_p        0.293713\n",
      "llm_rouge_1_f        0.306994\n",
      "llm_rouge_2_r        0.141714\n",
      "llm_rouge_2_p        0.100079\n",
      "llm_rouge_2_f        0.105389\n",
      "llm_rouge_l_r        0.300244\n",
      "llm_rouge_l_p        0.188993\n",
      "llm_rouge_l_f        0.198273\n",
      "llm_bleu_score       0.163098\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_names = ['context_precision', 'faithfulness', 'answer_relevancy', 'context_recall','rag_rouge_1_r','rag_rouge_1_p','rag_rouge_1_f','rag_rouge_2_r','rag_rouge_2_p','rag_rouge_2_f','rag_rouge_l_r','rag_rouge_l_p','rag_rouge_l_f','rag_bleu_score',\n",
    "                'llm_rouge_1_r','llm_rouge_1_p','llm_rouge_1_f','llm_rouge_2_r','llm_rouge_2_p','llm_rouge_2_f','llm_rouge_l_r','llm_rouge_l_p','llm_rouge_l_f','llm_bleu_score'\n",
    "                ]\n",
    "print(df[column_names].mean())\n",
    "df.to_csv('../data/rag_data/eval/evaleval_result_all.csv', index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2953512089618152, 0.21797452247345261)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([df[column_names].mean()[i] for i in ['rag_rouge_1_r','rag_rouge_1_p','rag_rouge_1_f','rag_rouge_2_r','rag_rouge_2_p','rag_rouge_2_f','rag_rouge_l_r','rag_rouge_l_p','rag_rouge_l_f','rag_bleu_score']])/10,\\\n",
    "sum([df[column_names].mean()[i] for i in ['llm_rouge_1_r','llm_rouge_1_p','llm_rouge_1_f','llm_rouge_2_r','llm_rouge_2_p','llm_rouge_2_f','llm_rouge_l_r','llm_rouge_l_p','llm_rouge_l_f','llm_bleu_score']])/10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
